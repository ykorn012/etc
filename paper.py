Big Data Capabilities Applied to Semiconductor Manufacturing Advanced Process Control

디지털 우주는 매 2 년마다 두 배씩 증가하고 있으며 2020 년까지 40,000 엑서 바이트 (40 조 기가 바이트)에 이를 것으로 예상됩니다 [1]. 데이터 생산량, 속도, 품질, 병합 및 분석에 대한 요구 사항이 반도체 제조에서 급격히 증가함에 따라 우리는 팹 전반에 걸쳐 데이터 관리 및 사용에 대한 새로운 접근법에 대한 필요성에 직면 해 있습니다. 이 문제는 여러 산업 분야에서 발생하고 있으며 이에 대응하여 "큰 데이터"노력이 대두되었습니다. 우리 업계에서는 대규모 데이터 솔루션이 Fault Detection and Classification (FDC)과 Run-to-Run (R2R) 제어 솔루션을 포함하는 고급 프로세스 제어 (APC) 솔루션을 미세 조정하여 제어 및 진단 수준을 높이는 데 핵심 역할을 합니다. 그러나 주된 영향은 Predictive Maintenance (PdM), 예측 스케줄링, Virtual Metrology (VM) 및 수율 예측과 같은 보다 효과적인 예측 기술을 더 잘 활용하는 것입니다 [2], [3].

SECTION I. Introduction

반도체에 대한 국제 기술 로드맵 (ITRS)은 큰 데이터 문제의 크기를 볼륨, 속도, 다양성 (즉, 데이터 병합), Veracity (데이터 품질) 및 Value (즉, , 분석) [3]. 대형 데이터 솔루션으로 전환하는 것은 다양한 레벨에서 5 개의 V를 처리하는 것입니다. 오늘날에는 대용량 데이터 또는 향상된 데이터 품질을 지원하기 위해 기존 시스템을 개선하여 때로는 이를 수행합니다. 그러나 장기적으로는 모든 제조가 다음과 같은 구성 요소를 포함하는 더 큰 데이터 친화적 솔루션으로 이동하게 될 것으로 예상됩니다. [5] :

- 실시간 수집 및 분석 : 증가 된 데이터 수집 속도 (Velocity) 외에도 시간 결정적 환경에서 실시간 의사 결정을 지원하는 분석 기능이 구현되고 있습니다.
- Apache Hadoop : Hadoop은 상용 하드웨어 클러스터에서 데이터 세트의 저장 및 대규모 처리를위한 오픈 소스 소프트웨어 프레임 워크를 제공합니다 [4]. Hadoop은 병렬 처리 및 확장성 기능을 활용하여 추적 데이터와 같은 대규모 시계열 데이터 세트에 적합한 솔루션을 제공합니다.
- Hadoop 분산 파일 시스템 (Hadoop Distributed Filing System, HDFS) : 대용량 데이터 볼륨 처리 및 가용성 극대화를 위해 특별히 설계되고 최적화 된 분산 파일 시스템입니다.
- MapReduce- 유형 프레임 워크 : 대규모 데이터 처리를 위해 프로그래밍 모델이 필요합니다. 예를 들어 MapReduce (처음에는 독점 Google 기술을 언급했지만 이후 일반화되었습니다)입니다.
- 데이터웨어 하우징 : 데이터 볼륨의 제한을 완화하는 확장 가능한 저장 기능이 필요합니다.
- 분석 : 대용량 데이터의 "가치"구성 요소를 처리함으로써 (특히 예측적인) 분석을 통해 대용량 데이터를 신속하게 분석 할 수 있습니다.
이 논문에서는 APC 시스템을 위한 대형 데이터 솔루션으로의 전환을 설명하고 이점을 설명합니다. 특히 II 장에서는 APC 용 빅 데이터 솔루션으로 이동할 때 고려해야 할 사항을 논의하고 빅 데이터 솔루션 구성의 성능을 기존 관계형 시스템과 비교하는 평가가 제공됩니다. 섹션 III에서는 기존 APC 기능이 큰 데이터 개선을 통해 활용할 수 있는 몇 가지 이점을 간략하게 설명하고 예측 솔루션의 기능을 개선하고 심지어 활성화하는 데 큰 역할을 하는 역할에 대해서는 IV 절에서 설명합니다. 또한 이 논문에서는 V 섹션의 팹에 대한 대용량 데이터 솔루션의 장기 마이그레이션 경로에 대해 설명하고 큰 데이터 진화의 일부가 될 것으로 예상되는 향후 방향 및 기회를 살펴 봅니다.

SECTION II. Implementing an APC Big Data Solution

A. Design Considerations: Hadoop Ecosystem Customized to Semiconductor Manufacturing Requirements
반도체 제조 데이터는 다양한 수준의 구조를 가지며 다중 서명으로 특징 지어 질 수 있습니다. 전통적인 관계형 기술에 비해 저장 효율성과 쿼리 성능을 향상시키기 위해 쓰기 빈도와 요구되는 읽기 횟수에 따라 다양한 구조가 사용됩니다. 예를 들어, 도 1에 도시 된 솔루션 접근법에서, 1 회 기입, 판독 - 다수의 요구를 갖는 데이터 카테고리에 대해 원주 형 저장 접근법이 적용된다. write-many, read-many로 특징 지워지는 데이터는 압축, 메모리 내 작업 및 확률적으로 대량의 sparse 데이터를 저장하는 내결함성있는 방법을 제공하는 오픈 소스 비 관계형 분산 데이터베이스 인 HBase에 저장됩니다 필터는 컬럼 단위로 적용된다 [5].

Fig. 1. Illustration of different big data storage mechanisms used to address data that has the requirement of write-once read-many (top), and write-many read-many (bottom).

대부분의 응용 프로그램은 두 가지 범주의 상점에서 효율적이고 투명하며 병렬로 데이터를 검색해야 합니다. 분산 쿼리 엔진 (임팔라)과 원시 Hadoop 데이터 처리 기술은 그림 2와 같이 이 용도로 사용됩니다. 

Fig. 2. Distributed query engine to support real-time and batch queries; HDFS—Hadoop Distributed File System, HQL—HBase Query Language [5].

B. Design Considerations: Providing a Migration Path for Existing APC Systems
Fault Detection (FD) 및 Run-to-run (R2R) 제어를 포함한 구성 요소로 구성된 APC 시스템은 오늘날의 팹에서 보급되어 있으며 광범위한 데이터 수집 및 관리 환경을 활용합니다 [7] - [8] [9]. 이러한 구성은 일반적으로 관계형 데이터베이스와 같은 기존의 Hadoop 이전 기술을 사용합니다. 하둡 생태계로 이동하려면 기존 시스템에서 원활하게 전환 할 수 있는 마이그레이션 경로를 제공해야합니다. 예를 들어, 현재 E3 ™ APC 시스템 (Applied Materials의 그림 3)은 구성 및 런타임 대량 데이터의 저장을 위해 Oracle 데이터베이스를 사용합니다. 대용량 데이터 아키텍처로의 마이그레이션을 용이하게 하기 위해 실행 데이터가 Hive / HBase 테이블의 Oracle 데이터베이스와 Hadoop 클러스터에 동시에 쓰여지는 메커니즘이 제공됩니다. E3 어플리케이션은 Impala SQL1과 ODBC2 드라이버를 사용하여 Hadoop 클러스터로부터 데이터를 가져옵니다. 장기간에 걸쳐 저장된 관계형 데이터는 필요하지 않으므로 (Hadoop에서 복제되기 때문에) 관련 관계형 구성 요소가 제거됩니다. 이러한 큰 데이터 솔루션에는 관계형 데이터베이스에 가장 적합한 트랜잭션 구성 요소가 여전히 필요할 것입니다. 그러나 대다수의 데이터 볼륨 및 처리는 Hadoop 유형의 인프라로 강등 될 수 있으며 반드시 처리해야 합니다. 관계형 및 대형 데이터 기반 구조의 공존에 대한 로드맵은 섹션 IV에서 자세히 설명합니다.

유지되어야 하는 관계형 인프라의 수준을 결정하는 열쇠는 시스템이 수행 할 데이터 분석의 응답 시간 요구 사항을 이해하는 것입니다. 일반적인 APC 시스템은 광범위한 오프라인 데이터 마이닝 기능을 지원해야 하지만 시간 결정적 분석 (예 : 방금 완료된 레서피 단계의 데이터 진단), 시간 결정적인 제어 규칙 (종종 "전략"이라고도 함)의 실행을 지원해야 합니다. FD 알람에 응답하여 툴을 종료), 실시간 분석 및 제어 규칙 실행 (예 : 종단점 탐지를 위한 "인라인"FD) 등이 있습니다. 오늘날 Hadoop은 광범위한 오프라인 데이터 마이닝에 적합합니다. 그러나 현재 Hadoop은 시간에 민감한 데이터 분석 (예 : 몇 초 또는 2 초 미만의 응답 시간 요구 사항)에 적합하지 않으므로 시스템의 관계형 데이터베이스 부분을 강등해야 컨트롤에 대한 데이터 및 분석을 지원할 수 있습니다 규칙 논리와 현재와 과거의 몇 번의 실행. 그림 3에 표시된 구조는 애플리케이션 환경의 세부 사항과 시간 경과에 따른 환경 마이그레이션을 지원하기 위해 적절하게 이 분할을 허용합니다. 또한 Hadoop 에코 시스템에서 시스템의 시간에 민감한 응답 부분으로의 피드백을 지원합니다 (예 : 히스토리 데이터 마이닝 결과를 기반으로 실시간 모니터링 조건을 조정).

C. Evaluation

대용량 데이터 솔루션의 적절한 구현은 보다 효율적인 데이터 저장 및 처리를 제공해야 합니다. 위에서 설명한 구현은 오늘날 전형적인 하이 엔드 팹에 있는 것을 대표하는 전통적인 관계형 시스템에 대해 평가되었습니다. 결과는 표 I 및 II 및도 1 및 2에 요약되어있다. 표 1은 관계형에서 하둡으로 이동함에 있어 스토리지 요구 사항이 80 % 이상 감소되었음을 보여줍니다. 그림 4와 표 2는 상대적으로 짧은 (8, 24, 72 시간) 데이터 이력에 대한 쿼리의 처리 속도를 비교 한 결과를 보여줍니다. 모든 시나리오에서 데이터는 2Hz 속도로 캡처되었으며 쿼리는 25 개 (센서 + 컨텍스트) 추적으로 선택되었습니다. 성능 수치는 서버 측과 클라이언트 측의 시간을 반영합니다. 대부분의 경우 클라이언트 측 시간은 경과 시간 중 상당 부분 (데이터 기술 비교와 관련이 없음)이지만 비교를 일관되게 유지하기 위해 모든 경우에 대해 (서버 + 클라이언트) 시간을 모두 포함합니다 . 그림 5는 소유 비용 (COO)이 4.5 배 향상되면 Hadoop 생태계로 이전 할 수 있음을 보여줍니다. 이는 전반적인 스토리지 효율성 및 쿼리 처리 속도 향상으로 인해 일부 달성됩니다 [5].

처리 속도 (그림 4)와 관련하여 작은 데이터 히스토리를 통한 쿼리가 관계형 시스템이 성능 이점을 가질 수 있는 영역을 나타 내기 때문에 비교 분석이 필요합니다. 결과는 정규화된 컬럼 스토어와 전통적인 관계형 응답 시간을 가진 Hadoop이 이러한 쿼리 유형과 비슷하다는 것을 보여줍니다. 관계형 데이터는 전통적으로 정규화 된 테이블에 저장됩니다. 그러나 시계열 및 분석 작업 부하 유형의 경우 데이터를 비 표준화하고 참조 데이터와 시계열 데이터를 모두 하나의 정규화되지 않은 테이블 [10]에 저장하여 추가 쿼리 효율성을 얻을 수 있습니다. 이를 통해 연속적인 데이터 저장이 가능해 입출력 속도가 향상되고 쿼리 엔진이 작은 데이터 세트를 여러 노드로 보낼 필요가 없습니다. 결과는 더 작은 데이터 세트의 경우에도 정규화되지 않은 데이터로 더 나은 성능을 얻을 수 있음을 나타냅니다. 데이터 양이 늘어남에 따라 비정규 화의 이점이 더욱 두드러집니다. 쿼리의 데이터 기록 길이가 길어질수록 Hadoop은 관계형 시스템보다 성능이 우수합니다. 그 이유는 스토리지 및 데이터 액세스 특성이 대형 순차 데이터 집합에 대한 쿼리에 더 적합하기 때문입니다. 결론은 짧은 히스토리 쿼리에 대해서는 패널티가 거의 없거나 오랜 시간이 걸리는 쿼리의 이점이 있기 때문에 전반적으로 Hadoop이 관계형 시스템보다 뛰어난 성능을 발휘한다는 결론입니다.
일반적으로 Hadoop 인프라로 변환하면 (1) 데이터 솔루션의 소유 비용 절감, (2)보다 효율적인 데이터 저장, (3) 향상된 쿼리 처리 속도, (4) 향상된 분석 성능 등 여러 가지 이점이 있습니다. (5) 예측 분석을 보다 효과적으로 수행 할 수 있습니다. 위에서 언급했듯이 솔루션은 관계형 데이터베이스에 가장 적합한 소형 트랜잭션 구성 요소와 결합 된 Hadoop 에코 시스템이며, 후자는 시간에 비례 한 (즉, "실시간") 분석 및 관련 실행을 지원하는 데 사용됩니다.

