Big Data Capabilities Applied to Semiconductor Manufacturing Advanced Process Control

디지털 우주는 매 2 년마다 두 배씩 증가하고 있으며 2020 년까지 40,000 엑서 바이트 (40 조 기가 바이트)에 이를 것으로 예상됩니다 [1]. 데이터 생산량, 속도, 품질, 병합 및 분석에 대한 요구 사항이 반도체 제조에서 급격히 증가함에 따라 우리는 팹 전반에 걸쳐 데이터 관리 및 사용에 대한 새로운 접근법에 대한 필요성에 직면 해 있습니다. 이 문제는 여러 산업 분야에서 발생하고 있으며 이에 대응하여 "큰 데이터"노력이 대두되었습니다. 우리 업계에서는 대규모 데이터 솔루션이 Fault Detection and Classification (FDC)과 Run-to-Run (R2R) 제어 솔루션을 포함하는 고급 프로세스 제어 (APC) 솔루션을 미세 조정하여 제어 및 진단 수준을 높이는 데 핵심 역할을 합니다. 그러나 주된 영향은 Predictive Maintenance (PdM), 예측 스케줄링, Virtual Metrology (VM) 및 수율 예측과 같은 보다 효과적인 예측 기술을 더 잘 활용하는 것입니다 [2], [3].

SECTION I. Introduction

반도체에 대한 국제 기술 로드맵 (ITRS)은 큰 데이터 문제의 크기를 볼륨, 속도, 다양성 (즉, 데이터 병합), Veracity (데이터 품질) 및 Value (즉, , 분석) [3]. 대형 데이터 솔루션으로 전환하는 것은 다양한 레벨에서 5 개의 V를 처리하는 것입니다. 오늘날에는 대용량 데이터 또는 향상된 데이터 품질을 지원하기 위해 기존 시스템을 개선하여 때로는 이를 수행합니다. 그러나 장기적으로는 모든 제조가 다음과 같은 구성 요소를 포함하는 더 큰 데이터 친화적 솔루션으로 이동하게 될 것으로 예상됩니다. [5] :

- 실시간 수집 및 분석 : 증가 된 데이터 수집 속도 (Velocity) 외에도 시간 결정적 환경에서 실시간 의사 결정을 지원하는 분석 기능이 구현되고 있습니다.
- Apache Hadoop : Hadoop은 상용 하드웨어 클러스터에서 데이터 세트의 저장 및 대규모 처리를위한 오픈 소스 소프트웨어 프레임 워크를 제공합니다 [4]. Hadoop은 병렬 처리 및 확장성 기능을 활용하여 추적 데이터와 같은 대규모 시계열 데이터 세트에 적합한 솔루션을 제공합니다.
- Hadoop 분산 파일 시스템 (Hadoop Distributed Filing System, HDFS) : 대용량 데이터 볼륨 처리 및 가용성 극대화를 위해 특별히 설계되고 최적화 된 분산 파일 시스템입니다.
- MapReduce- 유형 프레임 워크 : 대규모 데이터 처리를 위해 프로그래밍 모델이 필요합니다. 예를 들어 MapReduce (처음에는 독점 Google 기술을 언급했지만 이후 일반화되었습니다)입니다.
- 데이터웨어 하우징 : 데이터 볼륨의 제한을 완화하는 확장 가능한 저장 기능이 필요합니다.
- 분석 : 대용량 데이터의 "가치"구성 요소를 처리함으로써 (특히 예측적인) 분석을 통해 대용량 데이터를 신속하게 분석 할 수 있습니다.
이 논문에서는 APC 시스템을 위한 대형 데이터 솔루션으로의 전환을 설명하고 이점을 설명합니다. 특히 II 장에서는 APC 용 빅 데이터 솔루션으로 이동할 때 고려해야 할 사항을 논의하고 빅 데이터 솔루션 구성의 성능을 기존 관계형 시스템과 비교하는 평가가 제공됩니다. 섹션 III에서는 기존 APC 기능이 큰 데이터 개선을 통해 활용할 수 있는 몇 가지 이점을 간략하게 설명하고 예측 솔루션의 기능을 개선하고 심지어 활성화하는 데 큰 역할을 하는 역할에 대해서는 IV 절에서 설명합니다. 또한 이 논문에서는 V 섹션의 팹에 대한 대용량 데이터 솔루션의 장기 마이그레이션 경로에 대해 설명하고 큰 데이터 진화의 일부가 될 것으로 예상되는 향후 방향 및 기회를 살펴 봅니다.

SECTION II. Implementing an APC Big Data Solution

A. Design Considerations: Hadoop Ecosystem Customized to Semiconductor Manufacturing Requirements
반도체 제조 데이터는 다양한 수준의 구조를 가지며 다중 서명으로 특징 지어 질 수 있습니다. 전통적인 관계형 기술에 비해 저장 효율성과 쿼리 성능을 향상시키기 위해 쓰기 빈도와 요구되는 읽기 횟수에 따라 다양한 구조가 사용됩니다. 예를 들어, 도 1에 도시 된 솔루션 접근법에서, 1 회 기입, 판독 - 다수의 요구를 갖는 데이터 카테고리에 대해 원주 형 저장 접근법이 적용된다. write-many, read-many로 특징 지워지는 데이터는 압축, 메모리 내 작업 및 확률적으로 대량의 sparse 데이터를 저장하는 내결함성있는 방법을 제공하는 오픈 소스 비 관계형 분산 데이터베이스 인 HBase에 저장됩니다 필터는 컬럼 단위로 적용된다 [5].

Fig. 1. Illustration of different big data storage mechanisms used to address data that has the requirement of write-once read-many (top), and write-many read-many (bottom).

대부분의 응용 프로그램은 두 가지 범주의 상점에서 효율적이고 투명하며 병렬로 데이터를 검색해야 합니다. 분산 쿼리 엔진 (임팔라)과 원시 Hadoop 데이터 처리 기술은 그림 2와 같이 이 용도로 사용됩니다. 

Fig. 2. Distributed query engine to support real-time and batch queries; HDFS—Hadoop Distributed File System, HQL—HBase Query Language [5].

B. Design Considerations: Providing a Migration Path for Existing APC Systems
Fault Detection (FD) 및 Run-to-run (R2R) 제어를 포함한 구성 요소로 구성된 APC 시스템은 오늘날의 팹에서 보급되어 있으며 광범위한 데이터 수집 및 관리 환경을 활용합니다 [7] - [8] [9]. 이러한 구성은 일반적으로 관계형 데이터베이스와 같은 기존의 Hadoop 이전 기술을 사용합니다. 하둡 생태계로 이동하려면 기존 시스템에서 원활하게 전환 할 수 있는 마이그레이션 경로를 제공해야합니다. 예를 들어, 현재 E3 ™ APC 시스템 (Applied Materials의 그림 3)은 구성 및 런타임 대량 데이터의 저장을 위해 Oracle 데이터베이스를 사용합니다. 대용량 데이터 아키텍처로의 마이그레이션을 용이하게 하기 위해 실행 데이터가 Hive / HBase 테이블의 Oracle 데이터베이스와 Hadoop 클러스터에 동시에 쓰여지는 메커니즘이 제공됩니다. E3 어플리케이션은 Impala SQL1과 ODBC2 드라이버를 사용하여 Hadoop 클러스터로부터 데이터를 가져옵니다. 장기간에 걸쳐 저장된 관계형 데이터는 필요하지 않으므로 (Hadoop에서 복제되기 때문에) 관련 관계형 구성 요소가 제거됩니다. 이러한 큰 데이터 솔루션에는 관계형 데이터베이스에 가장 적합한 트랜잭션 구성 요소가 여전히 필요할 것입니다. 그러나 대다수의 데이터 볼륨 및 처리는 Hadoop 유형의 인프라로 강등 될 수 있으며 반드시 처리해야 합니다. 관계형 및 대형 데이터 기반 구조의 공존에 대한 로드맵은 섹션 IV에서 자세히 설명합니다.

유지되어야 하는 관계형 인프라의 수준을 결정하는 열쇠는 시스템이 수행 할 데이터 분석의 응답 시간 요구 사항을 이해하는 것입니다. 일반적인 APC 시스템은 광범위한 오프라인 데이터 마이닝 기능을 지원해야 하지만 시간 결정적 분석 (예 : 방금 완료된 레서피 단계의 데이터 진단), 시간 결정적인 제어 규칙 (종종 "전략"이라고도 함)의 실행을 지원해야 합니다. FD 알람에 응답하여 툴을 종료), 실시간 분석 및 제어 규칙 실행 (예 : 종단점 탐지를 위한 "인라인"FD) 등이 있습니다. 오늘날 Hadoop은 광범위한 오프라인 데이터 마이닝에 적합합니다. 그러나 현재 Hadoop은 시간에 민감한 데이터 분석 (예 : 몇 초 또는 2 초 미만의 응답 시간 요구 사항)에 적합하지 않으므로 시스템의 관계형 데이터베이스 부분을 강등해야 컨트롤에 대한 데이터 및 분석을 지원할 수 있습니다 규칙 논리와 현재와 과거의 몇 번의 실행. 그림 3에 표시된 구조는 애플리케이션 환경의 세부 사항과 시간 경과에 따른 환경 마이그레이션을 지원하기 위해 적절하게 이 분할을 허용합니다. 또한 Hadoop 에코 시스템에서 시스템의 시간에 민감한 응답 부분으로의 피드백을 지원합니다 (예 : 히스토리 데이터 마이닝 결과를 기반으로 실시간 모니터링 조건을 조정).

C. Evaluation

대용량 데이터 솔루션의 적절한 구현은 보다 효율적인 데이터 저장 및 처리를 제공해야 합니다. 위에서 설명한 구현은 오늘날 전형적인 하이 엔드 팹에 있는 것을 대표하는 전통적인 관계형 시스템에 대해 평가되었습니다. 결과는 표 I 및 II 및도 1 및 2에 요약되어있다. 표 1은 관계형에서 하둡으로 이동함에 있어 스토리지 요구 사항이 80 % 이상 감소되었음을 보여줍니다. 그림 4와 표 2는 상대적으로 짧은 (8, 24, 72 시간) 데이터 이력에 대한 쿼리의 처리 속도를 비교 한 결과를 보여줍니다. 모든 시나리오에서 데이터는 2Hz 속도로 캡처되었으며 쿼리는 25 개 (센서 + 컨텍스트) 추적으로 선택되었습니다. 성능 수치는 서버 측과 클라이언트 측의 시간을 반영합니다. 대부분의 경우 클라이언트 측 시간은 경과 시간 중 상당 부분 (데이터 기술 비교와 관련이 없음)이지만 비교를 일관되게 유지하기 위해 모든 경우에 대해 (서버 + 클라이언트) 시간을 모두 포함합니다 . 그림 5는 소유 비용 (COO)이 4.5 배 향상되면 Hadoop 생태계로 이전 할 수 있음을 보여줍니다. 이는 전반적인 스토리지 효율성 및 쿼리 처리 속도 향상으로 인해 일부 달성됩니다 [5].

처리 속도 (그림 4)와 관련하여 작은 데이터 히스토리를 통한 쿼리가 관계형 시스템이 성능 이점을 가질 수 있는 영역을 나타 내기 때문에 비교 분석이 필요합니다. 결과는 정규화된 컬럼 스토어와 전통적인 관계형 응답 시간을 가진 Hadoop이 이러한 쿼리 유형과 비슷하다는 것을 보여줍니다. 관계형 데이터는 전통적으로 정규화 된 테이블에 저장됩니다. 그러나 시계열 및 분석 작업 부하 유형의 경우 데이터를 비 표준화하고 참조 데이터와 시계열 데이터를 모두 하나의 정규화되지 않은 테이블 [10]에 저장하여 추가 쿼리 효율성을 얻을 수 있습니다. 이를 통해 연속적인 데이터 저장이 가능해 입출력 속도가 향상되고 쿼리 엔진이 작은 데이터 세트를 여러 노드로 보낼 필요가 없습니다. 결과는 더 작은 데이터 세트의 경우에도 정규화되지 않은 데이터로 더 나은 성능을 얻을 수 있음을 나타냅니다. 데이터 양이 늘어남에 따라 비정규 화의 이점이 더욱 두드러집니다. 쿼리의 데이터 기록 길이가 길어질수록 Hadoop은 관계형 시스템보다 성능이 우수합니다. 그 이유는 스토리지 및 데이터 액세스 특성이 대형 순차 데이터 집합에 대한 쿼리에 더 적합하기 때문입니다. 결론은 짧은 히스토리 쿼리에 대해서는 패널티가 거의 없거나 오랜 시간이 걸리는 쿼리의 이점이 있기 때문에 전반적으로 Hadoop이 관계형 시스템보다 뛰어난 성능을 발휘한다는 결론입니다.
일반적으로 Hadoop 인프라로 변환하면 (1) 데이터 솔루션의 소유 비용 절감, (2)보다 효율적인 데이터 저장, (3) 향상된 쿼리 처리 속도, (4) 향상된 분석 성능 등 여러 가지 이점이 있습니다. (5) 예측 분석을 보다 효과적으로 수행 할 수 있습니다. 위에서 언급했듯이 솔루션은 관계형 데이터베이스에 가장 적합한 소형 트랜잭션 구성 요소와 결합 된 Hadoop 에코 시스템이며, 후자는 시간에 비례 한 (즉, "실시간") 분석 및 관련 실행을 지원하는 데 사용됩니다.

SECTION III. Leveraging APC Big Data Capabilities for Improvement of Existing APC Capabilities
큰 데이터 개선은 FDC 및 R2R 제어 [11]를 포함한 오늘날의 설비에서 일반적으로 팹 전체에서 활용되는 기존 APC 기능을 향상시킬 수 있는 중요한 기회를 제공합니다. FDC 영역에서는 Variety, Veracity, Value 및 Velocity의 큰 데이터 기능을 활용하여 차세대 솔루션을 제공합니다. 이러한 솔루션은 오늘날의 FDC 솔루션으로 확인 된 주요 문제점 (모델링의 시간과 비용, 잘못된 수준의 오탐 (false alarm)과 실패한 포지티브 (missed fault)), (3) 모델 및 한계 관리. 그림 6에서 볼 수 있듯이 메트롤로지 또는 수율과 같은 공정 출력 품질 데이터를 FDC 솔루션에 통합하면 이러한 솔루션을 "감독되지 않음"에서 "감독 대상"으로 마이그레이션 할 수 있습니다. 이는 모델 및 심지어 한계 선택이 개발 중에 최적화 될 수 있고 앞서 언급 한 세 가지 문제점 모두를 해결하기 위해 자동화 된 방식으로 지속적인 개선 프로세스로 사용할 수 있음을 의미합니다 [11]. 또한 새로운 알고리즘과 높은 데이터 품질로 인해 모델 품질이 향상되고 데이터 수집 및 분석 속도가 높아지면 처리 중 FDC (흔히 "실시간"이라고 함) 및 많은 데이터를 수집하고 분석하는 FDC와 같은 기능을 사용할 수 있습니다 세분화 수준이 높습니다.
R2R 제어 영역에서 개선 된 데이터 수집 속도 및 세밀도 (속도)는 R2R 제어의보다 세부적인 제어 및 이동을 현장 제어 영역으로 가능하게 합니다. 이 후자의 기능은 직접 후 공정 계측을 위한 기회가 감소되는 더 많은 다층 장치 구조로 이동함에 따라 중요 할 것입니다 [11].

SECTION IV. Leveraging APC Big Data Capabilities for Prediction Solutions
예측 분석은 공장 자동화 인프라에 추가되는 기능의 최신 계층을 나타냅니다. 이러한 기능은 수율 최적화 및 전반적인 장비 효율성 (OEE) 개선을 위해 협업 방식으로 활용 될 수 있습니다. 생산량 최적화는 주로 독점적 인 노력이지만 OEE 개선은 장비, 프로세스 및 분석 지식을 함께 활용하여 비용 효율적이고 최적화 된 솔루션을 얻을 수 있도록 사용자, OEM 및 예측 분석 공급 업체 간의 협력이 필요합니다. 효과적인 예측 서비스를 제공하기 위해 기술 및 비즈니스 기반이 모두 존재할 수 있도록 이러한 당사자 간의 IP (지적 재산권) 분리 및 보호를 보장하는 기술이 필요합니다 [9]. 이러한 IP 및 보호 환경을 감안할 때 OEE에 영향을 미치는 예측 솔루션은 사용자, OEM 및 공급 업체 간의 협업 노력을 가장 먼저 활용할 수 있습니다. 이러한 PdM은 fab 전반에 걸친 최초의 예측 능력을 선도하는 것으로 보인다 [12,13].

A. Predictive Analytics and APC
예측 분석을 실현하기 위한 기술적 토대를 고려할 때, 예측 시스템은 APC 시스템의 출력물을 소비하며 그림 7에서 보듯이 이러한 APC 시스템의 향상에 대한 입력을 제공한다는 점에 유의해야 합니다. 예를 들어 가상 계측은 크게 의존합니다 on Fault Detection 모델 출력 데이터를 사용하여 계측 예측 모델을 개발 및 유지하지만 가상 계측 출력 예측을 사용하여 실행 간 제어 시스템의 기능을 향상시킬 수 있습니다 (예 : 로트 간 제어 시스템 웨이퍼 - 대 - 웨이퍼 제어 시스템으로) [14] - [15] [16]. 다른 일반적인 예측 및 관련 기술은 기능을 제공하기 위해 정기적으로 APC 애플리케이션과 자매 예측 애플리케이션을 활용합니다. 도 7에 도시 된 바와 같이, 이들은 (PdM 및 가상 메트롤로지에 추가하여) 다음을 포함한다 : (1) 가상 계측 및 R2R 제어를 포함하는 다수의 기술을 사용하여 녹색 대 녹색 시간을 감소시키는 녹색 대 녹색 애플리케이션 (2) 공정 제어, FDC 및 챔버 전반의 유지 보수 지식을 사용하여 챔버 작동을 보다 잘 일치시키고 최적화하기 위한 동적 온라인 챔버 매칭 (dynamic on-line chamber matching) [17], 그리고 (3) 장비를 사용하는 예측 어플리케이션 (FDC 정보 포함)을 사용하여 수율을 예측 한 다음 장비 R2R 제어 매개 변수, FDC 제한, WIP 일정 및 유지 관리 일정과 같은 항목 조정을 위한 권장 사항을 제공하여 팹 시스템을 수율 및 처리량 목표에 맞게 최적화하는 것이 좋습니다 [18].


